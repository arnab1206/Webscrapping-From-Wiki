# Webscrapping-From-Wiki

Webscrapping from wikipedia using Python

Web scraping is an automatic process of extracting information from web. Web scraping is also called as web data mining or web harvesting, is the process of constructing an agent which can extract, parse, download and organize useful information from the web automatically.

Leveraging Python's amazing tools to scrape data from other wikipedia with BeautifulSoup4 python package.

Final code is Webscrapping from wikipedia.ipynb 

# Steps of WebScraping

Step 1: Importing Contents from Web Pages

In this step, a web scraper will download the requested contents from multiple web pages.

Step 2: Extracting Data

The data on websites is HTML and mostly unstructured. Hence, in this step, web scraper will parse and extract structured data from the downloaded contents.

Step 3: Storing the Data

Here, a web scraper will store and save the extracted data in any of the format like CSV, JSON or in database.

Step 4: Analyzing the Data

After all these steps are successfully done, the web scraper will analyze the data thus obtained.

# What you will learn from this post:

    1. basic understanding of web scraping
    2. how to extract data from a website using classes and HTML tags
    3. how to use requests module to get data
    4. how to use Beautifulsoup

# Requirements:

    1. python3
    2. requests
    3. bs4

# Installation:

    1. sudo apt-get python3-pip
    2.pip3 install requests
    3. pip3 install bs4
